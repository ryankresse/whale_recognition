{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from utils import *\n",
    "import vgg16\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Dropout, Flatten, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import log_loss\n",
    "%matplotlib inline\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(), 'data', 'whale')\n",
    "img_dir  = os.path.join(os.getcwd(), 'data', 'whale', 'imgs')\n",
    "batch_size=64\n",
    "num_class = 447\n",
    "img_shape=(3, 224, 224)\n",
    "target_size = (224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_conv = [i for i, v in enumerate(vgg.model.layers) if type(v) is Conv2D][-1]\n",
    "\n",
    "conv_layers = vgg.model.layers[:last_conv+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Lambda at 0x7fa3a5606fd0>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7fa3a5374e10>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7fa3aa003310>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7fa3a52abb50>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7fa3a52d67d0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7fa3a5374bd0>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7fa3a52e3ad0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7fa3a52eeed0>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7fa3a533bad0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7fa3a5346b90>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7fa3a52e3a90>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7fa3a5348b10>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7fa3a425f710>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7fa3a4293990>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7fa3a421da50>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7fa3a421bc10>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7fa3a421b150>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7fa3a5348ad0>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7fa3a41fac90>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7fa3a4204d50>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7fa3a420bed0>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7fa3a420b710>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7fa3a415ad10>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7fa3a4163dd0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7fa3a41fac50>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7fa3a418d110>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7fa3a4117510>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7fa3a413f110>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7fa3a41461d0>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7fa3a40e9390>,\n",
       " <keras.layers.convolutional.Convolution2D at 0x7fa3a40f5450>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in conv_model.layers: layer.trainable=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tr_batches(dr = img_dir+ '/train', gen = ImageDataGenerator(), batch_size=batch_size):\n",
    "    return gen.flow_from_directory(dr, shuffle=True, target_size=target_size, batch_size=64)\n",
    "\n",
    "def get_val_batches(dr = img_dir+ '/valid', gen = ImageDataGenerator(), batch_size=batch_size):\n",
    "    return gen.flow_from_directory(dr, shuffle=False, target_size=target_size, batch_size=batch_size)\n",
    "\n",
    "def get_test_batches(dr = img_dir+ '/test', gen = ImageDataGenerator(), batch_size=batch_size):\n",
    "    return gen.flow_from_directory(dr, shuffle=False, target_size=target_size, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3635 images belonging to 447 classes.\n"
     ]
    }
   ],
   "source": [
    "tr_b = get_tr_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 909 images belonging to 447 classes.\n"
     ]
    }
   ],
   "source": [
    "val_b = get_val_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_conv_tr = conv_model.predict_generator(tr_b, tr_b.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg_conv_val = conv_model.predict_generator(val_b, val_b.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_array('vgg_conv_tr.bc', vgg_conv_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_array('vgg_val_tr.bc', vgg_conv_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_classes = tr_b.classes\n",
    "save_array('whale_tr_classes.bc', tr_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_classes = val_b.classes\n",
    "save_array('whale_val_classes.bc', val_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6925 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_b = get_test_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_conv_test = conv_model.predict_generator(test_b, test_b.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_array('vgg_conv_test.bc', vgg_conv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
